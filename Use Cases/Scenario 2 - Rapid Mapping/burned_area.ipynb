{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the provider, one of 'CREODIAS', 'MUNDI', 'ONDA' and 'SOBLOO'\n",
    "# There is only special processing for SOBLOO\n",
    "provider = 'SOBLOO'\n",
    "\n",
    "# Specific settings for SOBLOO\n",
    "sobloo_api_key = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input definition\n",
    "\n",
    "Define the area of interest (as WKT) and the identifiers of the pre- and post-event Sentinel-2 products.\n",
    "\n",
    "**Attention:** Execute only one of the following cells. For Sobloo, use the second one if the first data is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_wkt = 'POLYGON((-7.693 40.103,-7.237 40.103,-7.237 40.399,-7.693 40.399,-7.693 40.103))'\n",
    "\n",
    "input_identifiers = ('S2A_MSIL2A_20201026T112151_N0214_R037_T29TPE_20201027T144218',\n",
    "                     'S2B_MSIL2A_20201130T112429_N0214_R037_T29TPE_20201130T131854')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_wkt = 'POLYGON((-119.515 37.111,-119.515 37.308,-119.225 37.308,-119.225 37.111,-119.515 37.111))'\n",
    "\n",
    "input_identifiers = ('S2B_MSIL2A_20201202T184739_N0214_R070_T11SKB_20201202T205847',\n",
    "                     'S2A_MSIL2A_20201207T184751_N0214_R070_T11SKB_20201207T205922')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data path\n",
    "\n",
    "This path defines where the data is staged in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/workspace/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "This imports all the necessary python packages. Misconfigurations in the python environment can easily lead to problems. Pay particular attention to the **PREFIX** environment variable (the base path of the conda environment), which sets many other paths. It may be necessary that you have to create a new environment based on the environment file in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snappy\n",
    "import os\n",
    "os.environ['PREFIX'] = '/home/cloud/.conda/envs/env_burned_area/'\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['PREFIX'], 'conda-otb/lib/python'))\n",
    "os.environ['OTB_APPLICATION_PATH'] = os.path.join(os.environ['PREFIX'], 'conda-otb/lib/otb/applications')\n",
    "os.environ['GDAL_DATA'] =  os.path.join(os.environ['PREFIX'], 'share/gdal')\n",
    "os.environ['PROJ_LIB'] = os.path.join(os.environ['PREFIX'], 'share/proj')\n",
    "os.environ['GPT_BIN'] = os.path.join(os.environ['PREFIX'], 'snap/bin/gpt')\n",
    "os.environ['_JAVA_OPTIONS'] = '-Xms1g -Xmx1g'\n",
    "os.environ['LD_LIBRARY_PATH'] = '.'\n",
    "\n",
    "import otbApplication\n",
    "import gdal\n",
    "\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import box, shape, mapping\n",
    "from shapely.errors import ReadingError\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "gdal.UseExceptions()\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data download\n",
    "\n",
    "Execute the appropriate cell according to the value of `provider`.\n",
    "\n",
    "At the end of the output, the total duration of the data download is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for SOBLOO\n",
    "url_regex = re.compile('.*\\.SAFE(/(?P<dir>[^\\?]*))?(/(?P<file>[^/\\?]+))(\\?.*)?')\n",
    "\n",
    "if provider == 'SOBLOO':\n",
    "    time_start = datetime.utcnow()\n",
    "    for id in input_identifiers:\n",
    "        print(\"Product: {0}\".format(id))\n",
    "        response = requests.post(\"https://sobloo.eu/api/v1-beta/direct-data/product-links\",\n",
    "                          headers = {'Authorization': 'Apikey {0}'.format(sobloo_api_key)},\n",
    "                          json={'product': id, \"regexp\": \".*(B0[238]|B8A|B1[12]|manifest).*|.*\\.xml\"}\n",
    "                          #json={'product': id, \"regexp\": \"(.*)\"}\n",
    "                         )\n",
    "        \n",
    "        result = json.loads(response.text)\n",
    "        \n",
    "        download_list = [ l['url'] for l in result['links'] ]\n",
    "        for url in download_list:\n",
    "            m = url_regex.match(url)\n",
    "            if not m:\n",
    "                raise('Unrecognised URL pattern: {0}'.format(url))\n",
    "\n",
    "            file_dir = \"{0}/{0}.SAFE{1}{2}\".format(id, '/' if m.group('dir') else '', m.group('dir') if m.group('dir') else '')\n",
    "            file_name = m.group('file')\n",
    "\n",
    "            print(\"- Downloading {0}\".format(file_name))\n",
    "            Path(\"{0}/{1}\".format(data_path, file_dir)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            location = \"{0}/{1}/{2}\".format(data_path, file_dir, file_name)\n",
    "            r = requests.get(url, stream=True)\n",
    "            with open(location, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192): \n",
    "                    f.write(chunk)\n",
    "            r.close()\n",
    "\n",
    "    time_end = datetime.utcnow()\n",
    "    \n",
    "    print(\"Download duration: {0} seconds\".format(round((time_end - time_start).total_seconds(), 3)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain metadata\n",
    "\n",
    "Extract the metadata of the input products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as etree\n",
    "\n",
    "namespaces = {\n",
    "    'xfdu': 'urn:ccsds:schema:xfdu:1',\n",
    "    'safe': 'http://www.esa.int/safe/sentinel/1.1',\n",
    "    'gml': 'http://www.opengis.net/gml',\n",
    "}\n",
    "\n",
    "metadata = []\n",
    "\n",
    "for id in input_identifiers:\n",
    "    with open('{0}/{1}/{1}.SAFE/manifest.safe'.format(data_path, id), 'rb') as manifest:\n",
    "        manifest_xml = etree.fromstring(manifest.read())\n",
    "\n",
    "    metadata_elem = manifest_xml.xpath('/xfdu:XFDU/metadataSection', namespaces=namespaces)[0]\n",
    "\n",
    "    startdate = metadata_elem.xpath('metadataObject/metadataWrap/xmlData/safe:acquisitionPeriod/safe:startTime', namespaces=namespaces)[0].text\n",
    "    enddate = startdate\n",
    "    orbitDirection = metadata_elem.xpath('metadataObject/metadataWrap/xmlData/safe:orbitReference/safe:orbitNumber', namespaces=namespaces)[0].get('groundTrackDirection').upper()\n",
    "    coordinates = metadata_elem.xpath('metadataObject/metadataWrap/xmlData/safe:frameSet/safe:footPrint/gml:coordinates', namespaces=namespaces)[0].text.split(' ')\n",
    "    wkt = []\n",
    "    for i in range(len(coordinates) // 2):\n",
    "        wkt.append(\"{0} {1}\".format(coordinates[2 * i + 1], coordinates[2 * i]))\n",
    "\n",
    "    metadata.append(\n",
    "        {\n",
    "            'identifier': id,\n",
    "            'startdate': startdate,\n",
    "            'enddate': enddate,\n",
    "            'orbitDirection': orbitDirection,\n",
    "            'wkt': 'POLYGON(({0}))'.format(','.join(wkt))\n",
    "        }\n",
    "    )\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in metadata:\n",
    "    row['wkt'] = loads(row['wkt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = loads(aoi_wkt)\n",
    "(min_lon, min_lat, max_lon, max_lat) = aoi.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aoi)\n",
    "print (isinstance(aoi, str))\n",
    "for row in metadata:\n",
    "    ext = analyse(row, aoi, data_path)\n",
    "    \n",
    "for row in metadata:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composites = []\n",
    "\n",
    "bands = ['B12', 'B11', 'B8A']\n",
    "\n",
    "for row in metadata:\n",
    "    vrt_bands = []\n",
    "    \n",
    "    for j, band in enumerate(bands):\n",
    "        \n",
    "        vrt_bands.append(get_band_path(row, band))\n",
    "    \n",
    "    vrt = '{0}.vrt'.format(row['identifier'])\n",
    "    ds = gdal.BuildVRT(vrt,\n",
    "                       vrt_bands,\n",
    "                       srcNodata=0,\n",
    "                       xRes=10, \n",
    "                       yRes=10,\n",
    "                       separate=True)\n",
    "    ds.FlushCache()\n",
    "    \n",
    "    tif =  '{0}.tif'.format(row['identifier'])\n",
    "    \n",
    "    gdal.Translate(tif,\n",
    "                   vrt,\n",
    "                   projWin=[min_lon, max_lat, max_lon, min_lat],\n",
    "                   projWinSRS='EPSG:4326',\n",
    "                   outputType=gdal.GDT_Byte, \n",
    "                   scaleParams=[[0, 10000, 0, 255]])\n",
    "        \n",
    "        \n",
    "        \n",
    "    tif_e =  '{0}_NIR_SWIR_COMPOSITE.tif'.format(row['identifier'])\n",
    "    \n",
    "    try:\n",
    "        contrast_enhancement(tif, tif_e)\n",
    "\n",
    "        composites.append(tif_e)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "    \n",
    "    # os.remove(tif)\n",
    "    # os.remove(vrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed = []\n",
    "\n",
    "resample = dict()\n",
    "resample['referenceBandName'] = 'B2'\n",
    "\n",
    "reproject = dict()\n",
    "reproject['crs'] = 'EPSG:4326'\n",
    "\n",
    "subset = dict()\n",
    "subset['geoRegion'] = box(*aoi.bounds).wkt\n",
    "subset['copyMetadata'] = 'true'\n",
    "\n",
    "bands = '''<targetBands>\n",
    "    <targetBand>\n",
    "      <name>NDWI</name>\n",
    "      <type>float32</type>\n",
    "      <expression>(B3 - B8) / (B3 + B8)</expression>\n",
    "      <description/>\n",
    "      <unit/>\n",
    "      <noDataValue>NaN</noDataValue>\n",
    "    </targetBand>\n",
    "    <targetBand>\n",
    "      <name>NBR</name>\n",
    "      <type>float32</type>\n",
    "      <expression>(B8 - B12) / (B8 + B12)</expression>\n",
    "      <description/>\n",
    "      <unit/>\n",
    "      <noDataValue>NaN</noDataValue>\n",
    "    </targetBand>\n",
    "    <targetBand>\n",
    "      <name>valid_pixels</name>\n",
    "      <type>float32</type>\n",
    "      <expression>scl_vegetation or scl_not_vegetated ? 1 : 0</expression>\n",
    "      <description/>\n",
    "      <unit/>\n",
    "      <noDataValue>NaN</noDataValue>\n",
    "    </targetBand>\n",
    "    </targetBands>'''\n",
    "\n",
    "band_maths = dict()\n",
    "band_maths['targetBandDescriptors'] = bands \n",
    "\n",
    "\n",
    "\n",
    "for row in metadata:\n",
    "    print(os.path.join(row['local_path'], row['identifier'] + '.SAFE', 'MTD_MSIL2A.xml'))\n",
    "    \n",
    "    read = dict()\n",
    "    read['file'] = os.path.join(row['local_path'], row['identifier'] + '.SAFE', 'MTD_MSIL2A.xml') #, 'manifest.safe')\n",
    "    #read['formatName'] = 'SENTINEL-2-MSI-MultiRes-UTM52N'\n",
    "    \n",
    "    write = dict()\n",
    "    write['file'] = 'pre_{}'.format(row['identifier'])\n",
    "\n",
    "    row['pre_proc'] = 'pre_{}'.format(row['identifier'])\n",
    "    \n",
    "    \n",
    "    pre_processed.append('pre_{}'.format(row['identifier']))\n",
    "\n",
    "    print(\"*******\")\n",
    "    print(\"IDENTIFIER = {0}\".format(row['identifier']))\n",
    "    print(\"READ = {0}\".format(read))\n",
    "    print(\"WRITE = {0}\".format(write))\n",
    "    print(\"*******\")\n",
    "    \n",
    "    \n",
    "    pre_processing(Read=read, \n",
    "                 Resample=resample, \n",
    "                 Reproject=reproject, \n",
    "                 Subset=subset,\n",
    "                 BandMaths=band_maths,\n",
    "                 Write=write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_path = \"{0}.dim\".format(min((r['pre_proc'] for r in metadata)))\n",
    "slave_path = \"{0}.dim\".format(max((r['pre_proc'] for r in metadata)))\n",
    "\n",
    "#master_path='pre_S2B_MSIL2A_20201202T184739_N0214_R070_T11SKB_20201202T205847.dim'\n",
    "#slave_path='pre_S2A_MSIL2A_20201207T184751_N0214_R070_T11SKB_20201207T205922.dim'\n",
    "\n",
    "print(master_path)\n",
    "print(slave_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph = GraphProcessor(os.path.join(os.environ['PREFIX'], 'snap/bin/gpt'))\n",
    "operator = 'Read'\n",
    "\n",
    "node_id = 'Read_M'\n",
    "\n",
    "source_node_id = ''\n",
    "\n",
    "parameters = get_operator_default_parameters(operator)\n",
    "     \n",
    "parameters['file'] = master_path \n",
    "    \n",
    "mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "\n",
    "operator = 'Read'\n",
    "\n",
    "node_id = 'Read_S'\n",
    "\n",
    "source_node_id = ''\n",
    "\n",
    "parameters = get_operator_default_parameters(operator)\n",
    "     \n",
    "parameters['file'] = slave_path   \n",
    "    \n",
    "mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "\n",
    "operator = 'Collocate'\n",
    "\n",
    "parameters = get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['masterComponentPattern'] = 'PRE_FIRE_${ORIGINAL_NAME}'\n",
    "parameters['slaveComponentPattern'] = 'POST_FIRE_${ORIGINAL_NAME}'\n",
    "\n",
    "source_node_id = dict()\n",
    "\n",
    "source_node_id['master'] = 'Read_M'\n",
    "\n",
    "source_node_id['slave'] = 'Read_S'\n",
    "\n",
    "\n",
    "node_id = 'Collocate'\n",
    "\n",
    "mygraph.add_node(operator, operator,  parameters, source_node_id)\n",
    "\n",
    "operator = 'Write'\n",
    "\n",
    "node_id = 'Write'\n",
    "\n",
    "source_node_id = 'Collocate'\n",
    "\n",
    "\n",
    "\n",
    "parameters = get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['file'] = 'collocated'\n",
    "parameters['formatName'] = 'BEAM-DIMAP'\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.save_graph(filename='graph.xml')\n",
    "mygraph.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = 'burned_area_{0}_{1}'.format(datetime.strptime(min(r['enddate'] for r in metadata)[:19], '%Y-%m-%dT%H:%M:%S').strftime('%Y%m%d_%H%M%S'),\n",
    "                                          datetime.strptime(max(r['enddate'] for r in metadata)[:19], '%Y-%m-%dT%H:%M:%S').strftime('%Y%m%d_%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocated_input = 'collocated.dim'\n",
    "\n",
    "read = dict()\n",
    "read['file'] = collocated_input\n",
    "\n",
    "bands = '''<targetBands>\n",
    "    <targetBand>\n",
    "      <name>dNBR</name>\n",
    "      <type>float32</type>\n",
    "      <expression>(PRE_FIRE_valid_pixels == 1 and POST_FIRE_valid_pixels == 1 and ((PRE_FIRE_NBR - POST_FIRE_NBR) / (PRE_FIRE_NBR + 1.001)) > 0.27) ? PRE_FIRE_NBR - POST_FIRE_NBR : -999</expression>\n",
    "      <description/>\n",
    "      <unit/>\n",
    "      <noDataValue>NaN</noDataValue>\n",
    "    </targetBand>\n",
    "    <targetBand>\n",
    "      <name>RBR</name>\n",
    "      <type>float32</type>\n",
    "      <expression>(PRE_FIRE_valid_pixels == 1 and POST_FIRE_valid_pixels == 1 and ((PRE_FIRE_NBR - POST_FIRE_NBR) / (PRE_FIRE_NBR + 1.001)) > 0.27) ? ((PRE_FIRE_NBR - POST_FIRE_NBR) / (PRE_FIRE_NBR + 1.001)) : -999</expression>\n",
    "      <description/>\n",
    "      <unit/>\n",
    "      <noDataValue>NaN</noDataValue>\n",
    "    </targetBand>\n",
    "    <targetBand>\n",
    "      <name>valid_pixels</name>\n",
    "      <type>float32</type>\n",
    "      <expression>PRE_FIRE_valid_pixels == 1 and POST_FIRE_valid_pixels == 1</expression>\n",
    "      <description/>\n",
    "      <unit/>\n",
    "      <noDataValue>NaN</noDataValue>\n",
    "    </targetBand>\n",
    "    </targetBands>'''\n",
    "\n",
    "band_maths = dict()\n",
    "band_maths['targetBandDescriptors'] = bands \n",
    "\n",
    "write = dict()\n",
    "write['file'] = output_name\n",
    "write['formatName'] = 'GeoTIFF'\n",
    "\n",
    "burned_area(Read=read, \n",
    "            BandMaths=band_maths,\n",
    "            Write=write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_names = ['dNBR',\n",
    "              'RBR',\n",
    "             'valid_pixels']\n",
    "\n",
    "expressions = ['PRE_FIRE_NDWI >= 0.0 ? 0 : ((PRE_FIRE_NBR - POST_FIRE_NBR) / (PRE_FIRE_NBR + 1.001)) > 0.27 ? PRE_FIRE_NBR - POST_FIRE_NBR : 0',\n",
    "               'PRE_FIRE_NDWI >= 0.0 ? 0 : ((PRE_FIRE_NBR - POST_FIRE_NBR) / (PRE_FIRE_NBR + 1.001)) > 0.27 ? ((PRE_FIRE_NBR - POST_FIRE_NBR) / (PRE_FIRE_NBR + 1.001)) : 0',\n",
    "              'PRE_FIRE_valid_pixels == 1 and POST_FIRE_valid_pixels == 1']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ds_temp = gdal.Open(output_name + '.tif',  gdal.OF_UPDATE)\n",
    "\n",
    "for band_index in range(ds_temp.RasterCount):\n",
    "\n",
    "    band_metadata = dict()\n",
    "    band_metadata['BAND_EXPRESSION'] = expressions[band_index]\n",
    "\n",
    "    src_band = ds_temp.GetRasterBand(band_index+1)\n",
    "    src_band.SetMetadata(band_metadata)\n",
    "    src_band.SetDescription(band_names[band_index])  \n",
    "\n",
    "ds_temp.FlushCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_threshold = 0.270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_palette = {-999: [0, 0, 0, 255],\n",
    "                    -1: [159, 159, 159, 0], # grey\n",
    "                    -0.5: [43, 25, 223, 0], # blue\n",
    "                    -0.251: [139, 221, 231, 0], # cyan\n",
    "                    -0.101: [97, 169, 45, 255], # unburned, green \n",
    "                    0.099: [250, 254, 76, 0], # yellow\n",
    "                    0.269: [228, 173, 55, 0], # orange\n",
    "                    0.439: [202, 59, 18, 0],  # red\n",
    "                    0.659: [85, 15, 112, 0]} # purple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster2rgb(output_name + '.tif',\n",
    "           severity_palette,\n",
    "           output_name + '.rgb.tif',\n",
    "           raster_band=1,\n",
    "           discrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "colors = [\"blue\", \"cyan\", \"green\",\"yellow\",\"orange\",\"red\",\"purple\"]\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list(\"mycmap\", colors)\n",
    "\n",
    "view_colormap(colors, cmap, '{0}.legend.png'.format(output_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dimap in ['collocated'] + [r['pre_proc'] for r in metadata]:\n",
    "    print(\"Delete {0}.dim\".format(dimap))\n",
    "    os.remove(dimap + '.dim')\n",
    "    print(\"Delete {0}.data\".format(dimap))\n",
    "    shutil.rmtree(dimap + '.data') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
